{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "from rootnet import rootnet\n",
    "from config import cfg\n",
    "from root_utils.pose_utils import process_bbox\n",
    "from dataset import generate_patch_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input image\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=cfg.pixel_mean, std=cfg.pixel_std)])\n",
    "img_path = 'input/18.jpg'\n",
    "original_img = cv2.imread(img_path)\n",
    "\n",
    "# resize image\n",
    "original_img = cv2.resize(original_img, (256,256), interpolation = cv2.INTER_AREA) \n",
    "original_img_height, original_img_width = original_img.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\abdor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-9-26 torch 1.9.0 CUDA:0 (GeForce GTX 1050 Ti, 4096.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "results = model(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.299999</td>\n",
       "      <td>160.900009</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>183.699997</td>\n",
       "      <td>0.815430</td>\n",
       "      <td>62</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.200005</td>\n",
       "      <td>157.100006</td>\n",
       "      <td>126.200005</td>\n",
       "      <td>219.199997</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>39.975002</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.800003</td>\n",
       "      <td>152.300003</td>\n",
       "      <td>168.800003</td>\n",
       "      <td>207.800003</td>\n",
       "      <td>0.751465</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.500000</td>\n",
       "      <td>155.600006</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>175.199997</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>62</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173.600006</td>\n",
       "      <td>122.400002</td>\n",
       "      <td>194.400009</td>\n",
       "      <td>186.400009</td>\n",
       "      <td>0.686035</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.837500</td>\n",
       "      <td>194.800003</td>\n",
       "      <td>55.049999</td>\n",
       "      <td>249.600006</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.300003</td>\n",
       "      <td>204.100006</td>\n",
       "      <td>102.900002</td>\n",
       "      <td>245.600006</td>\n",
       "      <td>0.548340</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.800003</td>\n",
       "      <td>12.231250</td>\n",
       "      <td>193.199997</td>\n",
       "      <td>0.499023</td>\n",
       "      <td>62</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>124.300003</td>\n",
       "      <td>191.900009</td>\n",
       "      <td>155.699997</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.492920</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146.699997</td>\n",
       "      <td>146.100006</td>\n",
       "      <td>160.699997</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>0.474365</td>\n",
       "      <td>62</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>154.800003</td>\n",
       "      <td>199.800003</td>\n",
       "      <td>186.600006</td>\n",
       "      <td>221.800003</td>\n",
       "      <td>0.326904</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85.700005</td>\n",
       "      <td>215.400009</td>\n",
       "      <td>125.700005</td>\n",
       "      <td>242.600006</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>63</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213.400009</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>220.199997</td>\n",
       "      <td>0.277832</td>\n",
       "      <td>63</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>152.300003</td>\n",
       "      <td>160.699997</td>\n",
       "      <td>168.900009</td>\n",
       "      <td>193.500000</td>\n",
       "      <td>0.260010</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xmin        ymin        xmax        ymax  confidence  class    name\n",
       "0    36.299999  160.900009   62.250000  183.699997    0.815430     62      tv\n",
       "1   103.200005  157.100006  126.200005  219.199997    0.776367      0  person\n",
       "2     0.075000  220.000000   39.975002  256.000000    0.767578     56   chair\n",
       "3   133.800003  152.300003  168.800003  207.800003    0.751465      0  person\n",
       "4    76.500000  155.600006   96.500000  175.199997    0.736328     62      tv\n",
       "5   173.600006  122.400002  194.400009  186.400009    0.686035      0  person\n",
       "6    23.837500  194.800003   55.049999  249.600006    0.589355     56   chair\n",
       "7    69.300003  204.100006  102.900002  245.600006    0.548340     56   chair\n",
       "8     0.000000  168.800003   12.231250  193.199997    0.499023     62      tv\n",
       "9   124.300003  191.900009  155.699997  223.000000    0.492920     56   chair\n",
       "10  146.699997  146.100006  160.699997  163.100006    0.474365     62      tv\n",
       "11  154.800003  199.800003  186.600006  221.800003    0.326904     56   chair\n",
       "12   85.700005  215.400009  125.700005  242.600006    0.308838     63  laptop\n",
       "13  213.400009  191.000000  243.000000  220.199997    0.277832     63  laptop\n",
       "14  152.300003  160.699997  168.900009  193.500000    0.260010     56   chair"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "res = pd.DataFrame()\n",
    "res = results.pandas().xyxy[0]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = res[res['name']=='person']\n",
    "persons = persons.assign(width = abs(persons['xmax'] - persons['xmin']))\n",
    "persons = persons.assign(hight = abs(persons['ymax'] - persons['ymin']))\n",
    "rootnet_input = persons.drop(['xmax','ymax','confidence','class','name'], axis=1)\n",
    "rects = rootnet_input.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RootNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_list = rootnet_input.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare bbox for each human\n",
    "#bbox_list = rootnet_input.values.tolist()  # xmin, ymin, width, height\n",
    "person_num = len(bbox_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focal length: (53, 53)\n",
      "principal points: (128.0, 128.0)\n"
     ]
    }
   ],
   "source": [
    "# normalized camera intrinsics\n",
    "focal = [53, 53] # x-axis, y-axis\n",
    "princpt = [original_img_width/2, original_img_height/2] # x-axis, y-axis\n",
    "print('focal length: (' + str(focal[0]) + ', ' + str(focal[1]) + ')')\n",
    "print('principal points: (' + str(princpt[0]) + ', ' + str(princpt[1]) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from ./snapshot_18.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model = rootnet.lood_model('./snapshot_%d.pth.tar' % int(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "roots= [] \n",
    "# for cropped and resized human image, forward it to RootNet\n",
    "for n in range(person_num):\n",
    "    bbox = process_bbox(np.array(bbox_list[n]), original_img_width, original_img_height)\n",
    "    img, img2bb_trans = generate_patch_image(original_img, bbox, False, 0.0) \n",
    "    img = transform(img).cuda()[None,:,:,:]\n",
    "    k_value = np.array([math.sqrt(cfg.bbox_real[0]*cfg.bbox_real[1]*focal[0]*focal[1]/(bbox[2]*bbox[3]))]).astype(np.float32)\n",
    "    k_value = torch.FloatTensor([k_value]).cuda()[None,:]\n",
    "\n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        root_3d = model(img, k_value) # x,y: pixel, z: root-relative depth (mm)\n",
    "    img = img[0].cpu().numpy()\n",
    "    root_3d = root_3d[0].cpu().numpy()\n",
    "    result.append(np.array([root_3d[0],root_3d[1],root_3d[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([       31.5,       40.66,      1005.3], dtype=float32),\n",
       " array([     27.882,      39.178,      916.41], dtype=float32),\n",
       " array([     32.316,      39.033,      1117.1], dtype=float32)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(p0,p1):\n",
    "    squared_dist = np.sum((p0-p1)**2)\n",
    "    dist = np.sqrt(squared_dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 88.946976, 111.87162], [88.946976, 0.0, 200.76688], [111.87162, 200.76688, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "distances = []\n",
    "for e in result:\n",
    "    distances.append([calc_distance(e,num) for num in result])\n",
    "\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_limit(mylist,dis):\n",
    "    flag =False\n",
    "    for i in mylist:\n",
    "        if i>0:\n",
    "            if i<= dis:\n",
    "                flag = True\n",
    "    return flag\n",
    "\n",
    "distance_flags = list(map( lambda x: distance_limit(x,100)  ,distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.destroyAllWindows()\n",
    "image = original_img.copy()\n",
    "cv2.namedWindow(\"output2\", cv2.WINDOW_NORMAL)    # Create window with freedom of dimensions\n",
    "#  BGR\n",
    "for i,flag in zip(range(len(rects)),distance_flags):\n",
    "    print(flag)\n",
    "    if flag:\n",
    "        image = cv2.rectangle(image, (int(rects[i][0]), int(rects[i][1])), (int(rects[i][0]+rects[i][2]), int(rects[i][1]+rects[i][3])), (0, 0, 255), 1)\n",
    "    else:\n",
    "        image = cv2.rectangle(image, (int(rects[i][0]), int(rects[i][1])), (int(rects[i][0]+rects[i][2]), int(rects[i][1]+rects[i][3])), (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "    #ax.add_patch(rect)\n",
    "cv2.imshow(\"output2\",image)\n",
    "\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "344bcc497839c1260a83db95ba8b6bbdfec0a5408df7b92f779a6be6e8b29402"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gpenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
